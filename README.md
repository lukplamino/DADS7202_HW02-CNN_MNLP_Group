# DADS7202_Group Assignment 2 CNN (Group_MNLP)
> Objective: **`What do you use to train an image classiffier with our custom image dataset?`**
## âœ¨Highlight
- 1...
- 2...
- 3...

<!-- à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸´à¸”à¹€à¸«à¹‡à¸™ à¸à¸²à¸£à¸„à¹‰à¸™à¸à¸š à¸‚à¹‰à¸­à¸ªà¸£à¸¸à¸›à¸«à¸£à¸·à¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ insight à¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆà¸—à¸µà¹ˆ  3-5 bullets -->

## Table of Contents

 - [1. IntroductionğŸ¯](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#1-introduction)
 - [2. DatağŸ“‘](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group#2-data)
 - [3. Network architectureğŸ“¦](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group#3-network-architecture)
 - [4. TrainingğŸ”®](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group#4-training)
 - [5. ResultsğŸ“ˆ](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group#5-results)
 - [6. DiscussionğŸ’­](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#6-discussion)
 - [7. ConclusionğŸ“Š](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#7-conclusion)
 - [8. ReferencesğŸŒ](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#8-references)
 - [Citing](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#citing)
 - [ğŸ‘¥ Members, Percent Contribution and Responsibility](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#-members-percent-contribution-and-responsibility)
 - [ğŸ–‡ï¸End Credit ](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#%EF%B8%8Fend-credit)



## 1. IntroductionğŸ¯ 

**`multi-class classification`**:

- This project aims to test 3**CNN pre-training models** (`VGG16`, `ResNet50V2`, `EfficientNetB7`) on the ImageNet dataset and fine-tune it to classify 4 types of bananas ğŸŒ (`Cultivated banana`, `Sugar banana`, `Lady finger banana`, `Cavendish banana`) which is our custom image dataset that were never trained on. 
- Then, we will compare performance of **3 CNN pre-training models** without transfer learning and with transfer learning (Fine-tuning).
- Finally, we use **`Grad-CAM`** technique to debug the model and gain more insight into what a trained CNN did.

 
## 2. DatağŸ“‘
There are many banana varieties in Thailand and each one of them has different characteristics. Letâ€™s find out interesting facts about different varieties of banana before training and finetuning models.

 ğŸŒ **1. Cultivated banana - à¸à¸¥à¹‰à¸§à¸¢à¸™à¹‰à¸³à¸§à¹‰à¸²**
  
  The fruit looks a little bit angled with a thick skin and a sweet flavor.
  
  <img src="https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/Images/Cultivated%20banana.png" style="width:120px;"/>
 
 ğŸŒ **2. Sugar banana - à¸à¸¥à¹‰à¸§à¸¢à¹„à¸‚à¹ˆ**
  
  The fruit is short and round. Its skin is thin with dark spots. 
  
  <img src="https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/Images/Sugar%20banana.png" style="width:120px;"/>
 
 ğŸŒ **3. Lady finger banana - à¸à¸¥à¹‰à¸§à¸¢à¹€à¸¥à¹‡à¸šà¸¡à¸·à¸­à¸™à¸²à¸‡**
  
  Lady finger banana is one of the smallest bananas. Its skin is thick with a soft flesh inside.
  
   <img src="https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/Images/Lady%20finger%20banana.png" style="width:120px;"/>
  
   
 ğŸŒ **4. Cavendish banana - à¸à¸¥à¹‰à¸§à¸¢à¸«à¸­à¸¡**
  
  The fruit is long with a thin skin. It offers a sweet flavor along with a uniquely pleasant smell.
  
  <img src="https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/Images/Cavendish%20banana.jpg" style="width:120px;"/>
 
#### ğŸ“Data source: 
- We use [**Download All Images**](https://chrome.google.com/webstore/detail/download-all-images/ifipmflagepipjokmbdecpmjbibjnakm?hl=en) extension in chrome web store to collect set of images by searching keywords (4 types of banana) from **`google image`** 

#### ğŸ§¹Data preparation:
- Collecting set of images from the Internet source is a quick and simple method to gather a set of images. Some facts, meanwhile, are not entirely accurate or useful. As a result, we have to manually remove several unnecessary images from the collection, such as banana dessert, banana trunk, other banana pieces, and duplicate images. Additionally, because the keyword and banana type are inconsistent, we need to recheck theÂ banana type labels.
- 
#### Data pre-processing: **`â•Data Augmentation`** 
<!-- à¹ƒà¸Šà¹‰ ImageDataGenerator or Random xx -->

#### âœ‚ï¸Data splitting (train/val/test):
- `random_state` =  
- `test_size` = 
- **`Train Shape`**: 
- **`Test Shape`**: 

[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)

## 3. Network architectureğŸ“¦

### Pre-training Models 
In this experiment,we have selected 3 Pre-training Models for fine-tuning

<img src="https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/Images/pre-training-models-info.png" style="width:550px;"/>

<!-- à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸•à¹ˆà¸²à¸‡ à¹† à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¹ƒà¸Šà¹‰ (à¹€à¸Šà¹ˆà¸™ à¸ˆà¸³à¸™à¸§à¸™à¹à¸¥à¸°à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸à¸²à¸£à¸§à¸²à¸‡ layer, à¸ˆà¸³à¸™à¸§à¸™ nodes, activation function, regularization) à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¸­à¸‡ network diagram à¸«à¸£à¸·à¸­à¸•à¸²à¸£à¸²à¸‡ (à¹‚à¸”à¸¢à¹ƒà¸ªà¹ˆà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸à¸­à¸—à¸µà¹ˆà¸„à¸™à¸—à¸µà¹ˆà¸¡à¸²à¸­à¹ˆà¸²à¸™ à¸ˆà¸°à¸ªà¸²à¸¡à¸²à¸£à¸–à¹„à¸›à¸ªà¸£à¹‰à¸²à¸‡ network à¸•à¸²à¸¡à¹€à¸£à¸²à¹„à¸”à¹‰) -->

[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)


## 4. TrainingğŸ”®
<!-- à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸‚à¸­à¸‡à¸à¸²à¸£ train à¹à¸¥à¸° validate à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸—à¸£à¸±à¸à¸¢à¸²à¸à¸£à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£ train à¹‚à¸¡à¹€à¸”à¸¥à¸«à¸™à¸¶à¹ˆà¸‡ à¹† à¹€à¸Šà¹ˆà¸™ training strategy (à¹€à¸Šà¹ˆà¸™ single loss, compound loss, two-step training, end-to-end training), loss, optimizer (learning rate, momentum, etc), batch size,
epoch, à¸£à¸¸à¹ˆà¸™à¹à¸¥à¸°à¸ˆà¸³à¸™à¸§à¸™ CPU à¸«à¸£à¸·à¸­ GPU à¸«à¸£à¸·à¸­ TPU à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰, à¹€à¸§à¸¥à¸²à¹‚à¸”à¸¢à¸›à¸£à¸°à¸¡à¸²à¸“à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ train à¹‚à¸¡à¹€à¸”à¸¥à¸«à¸™à¸¶à¹ˆà¸‡à¸•à¸±à¸§ à¸¯à¸¥à¸¯ -->
[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)

## 5. ResultsğŸ“ˆ
<!-- à¹à¸ªà¸”à¸‡à¸•à¸±à¸§à¹€à¸¥à¸‚à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹ƒà¸™à¸£à¸¹à¸›à¸‚à¸­à¸‡à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ meanÂ±SD à¹‚à¸”à¸¢à¹ƒà¸«à¹‰à¸—à¸³à¸à¸²à¸£à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸”à¹‰à¸§à¸¢ initial random weights à¸—à¸µà¹ˆà¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 3-5 à¸£à¸­à¸šà¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 3-5 à¹‚à¸¡à¹€à¸”à¸¥à¸¡à¸²à¸«à¸²à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸à¸±à¸™, à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸à¸²à¸£ train à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸›à¹‡à¸™à¸à¸£à¸²à¸Ÿà¹€à¸—à¸µà¸¢à¸š train vs. validation, à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸§à¹ˆà¸²à¹€à¸à¸´à¸” underfit à¸«à¸£à¸·à¸­ overfit à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ, à¸­à¸˜à¸´à¸šà¸²à¸¢ evaluation metric à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸šà¸™ train/val/test sets à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸‚à¸­à¸‡à¸›à¸±à¸à¸«à¸², à¸«à¸²à¸à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸£à¸²à¸à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥à¸­à¸·à¹ˆà¸™ à¹† (à¸‚à¸­à¸‡à¸„à¸™à¸­à¸·à¹ˆà¸™) à¸šà¸™ any standard benchmark dataset à¹„à¸”à¹‰à¸”à¹‰à¸§à¸¢à¸ˆà¸°à¸¢à¸´à¹ˆà¸‡à¸—à¸³à¹ƒà¸«à¹‰à¸‡à¸²à¸™à¸”à¸¹à¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­à¸¢à¸´à¹ˆà¸‡à¸‚à¸¶à¹‰à¸™ à¹€à¸Šà¹ˆà¸™ à¹€à¸—à¸µà¸¢à¸šà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³ à¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰train à¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ inference à¸šà¸™à¸‹à¸µà¸à¸µà¸¢à¸¹à¹à¸¥à¸°à¸ˆà¸µà¸à¸µà¸¢à¸¹ à¹€à¸—à¸µà¸¢à¸šà¸‚à¸™à¸²à¸”à¹‚à¸¡à¹€à¸”à¸¥ à¸¯à¸¥à¸¯ 

à¸à¸²à¸£à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹€à¸—à¸µà¸¢à¸š train vs. validation (à¹€à¸Šà¹ˆà¸™ loss, accuracy) à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¹„à¸›à¹„à¸”à¹‰à¸„à¸§à¸£à¹à¸ªà¸”à¸‡à¹„à¸§à¹‰à¹ƒà¸™à¸à¸£à¸²à¸Ÿà¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸—à¸µà¸¢à¸š scale à¸„à¹ˆà¸²à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹à¸¥à¸°à¸”à¸¹ underfit / overfit à¹„à¸”à¹‰à¸‡à¹ˆà¸²à¸¢-->
[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)


## 6. DiscussionğŸ’­
<!-- à¸­à¸ à¸´à¸›à¸£à¸²à¸¢à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸—à¸µà¹ˆà¹„à¸”à¹‰à¸§à¹ˆà¸²à¸¡à¸µà¸­à¸°à¹„à¸£à¹€à¸›à¹‡à¸™à¹„à¸›à¸•à¸²à¸¡à¸ªà¸¡à¸¡à¸•à¸´à¸à¸²à¸™ à¸«à¸£à¸·à¸­à¸¡à¸µà¸­à¸°à¹„à¸£à¸œà¸´à¸”à¸„à¸²à¸” à¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¹„à¸›à¸•à¸²à¸¡à¸ªà¸¡à¸¡à¸•à¸´à¸à¸²à¸™à¸šà¹‰à¸²à¸‡, à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¸§à¹ˆà¸²à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸œà¸´à¸”à¸„à¸²à¸”à¸«à¸£à¸·à¸­à¸œà¸´à¸”à¸›à¸à¸•à¸´à¸™à¸±à¹‰à¸™à¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸à¸´à¸”à¸ˆà¸²à¸à¸­à¸°à¹„à¸£, à¹ƒà¸™à¸à¸£à¸“à¸µà¸—à¸µà¹ˆ dataset à¸¡à¸µà¸›à¸±à¸à¸«à¸² (à¹€à¸Šà¹ˆà¸™à¸à¸£à¸“à¸µ imbalanced dataset) à¸„à¸§à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸”à¹‰à¸§à¸¢à¸§à¹ˆà¸²à¸§à¸´à¸˜à¸µà¹à¸à¹‰à¸—à¸µà¹ˆà¹€à¸£à¸²à¹ƒà¸Šà¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²à¸‚à¸­à¸‡ dataset à¹„à¸”à¹‰à¸ˆà¸£à¸´à¸‡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ -->

[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)

## 7. ConclusionğŸ“Š
<!-- à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸‚à¸­à¸‡à¸à¸²à¸£à¸šà¹‰à¸²à¸™à¸™à¸µà¹‰ à¹‚à¸”à¸¢à¹€à¸™à¹‰à¸™à¸à¸²à¸£à¸•à¸­à¸šà¹‚à¸ˆà¸—à¸¢à¹Œà¸›à¸±à¸à¸«à¸² (research question) à¸«à¸£à¸·à¸­à¸ˆà¸¸à¸”à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸«à¸¥à¸±à¸ (objective) à¸‚à¸­à¸‡à¸à¸²à¸£à¸šà¹‰à¸²à¸™à¹à¸•à¹ˆà¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡ -->
[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)

## 8. ReferencesğŸŒ
<!-- This content will not appear in the rendered Markdown -->
### Library
<!-- This content will not appear in the rendered Markdown -->
### Version
<!-- This content will not appear in the rendered Markdown -->
### References
- _-. (2019)._
[**à¹€à¸£à¸·à¹ˆà¸­à¸‡à¸à¸¥à¹‰à¸§à¸¢à¹†**](https://www.topspicks.tops.co.th/single-post/tidbits-about-bananas2019): Topspicks.
- _Lang, Steven and Bravo-Marquez, Felipe and Beckham, Christopher and Hall, Mark and Frank, Eibe. (2019)._ [**IMAGENET 1000 Class List**](https://deeplearning.cms.waikato.ac.nz/user-guide/class-maps/IMAGENET/). Github.
- _[fchollet](https://twitter.com/fchollet). (2020, May 12)._[**Transfer learning & fine-tuning**](https://keras.io/guides/transfer_learning/). Keras.
- **Keras Applications**](https://keras.io/api/applications/). Keras.

[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)

## Citing
[Bib.file](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/Citing_CNN_MNLP.bib)

```
@Misc{MNLP,
    AUTHOR          = {Navapol San. , Pakawut Kam. , Supisara Poo. , Kantima Tec.},
    TITLE           = {Model : CNN image classification model with finetuning on a custom dataset},
    YEAR            = {2022},
    howpublished    = "\url{https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group.git}"
}
```


[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)


## ğŸ‘¥ Members, Percent Contribution and Responsibility 
|No  |ID                |Name                              |% Contribution |Responsibility                             |
|:---:|:---:             |---                               |:---:            |:---|
|1.  |**`6410422002`**  |[Navapol San.](https://www.kaggle.com/navapol)                      |   **`25%`**     |**`Collecting data (Cavendish banana)`**, **`Train Model (EfficientNetB7)`**
|2.  |**`6410422003`**  |[Pakawut Kam.](https://www.kaggle.com/ppakawut)                     |   **`25%`**     |**`Collecting data (Lady finger banana)`**, **`Train Model (EfficientNetB7)`**  |
|3.  |**`6410422024`**  |[Supisara Poo.](https://www.kaggle.com/supisarapo)                     |   **`25%`**     |**`Collecting data (Cultivated banana)`**, **`Train Model (ResNet50V2)`**   |
|4.  |**`6410422027`**  |[Kantima Tec.](https://www.kaggle.com/kantimatec)                     |   **`25%`**     |**`Collecting data (Sugar banana)`**, **`Train Model (VGG16)`**  |


[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)


## ğŸ–‡ï¸End Credit 
This project is a part of **`DADS7202 Deep Learning`**

Term: 1 Year of education: 2022

ğŸ“Master of Science Program in **`Data Analytics and Data Science`** (DADS)

ğŸ«National Institute of Development Administration (**`NIDA`**)



[ğŸ”](https://github.com/lukplamino/DADS7202_HW02-CNN_MNLP_Group/blob/main/README.md#highlight)


----------------------------------------------
<!--
â‘ Github link (public access) 1 à¸¥à¸´à¸‡à¸à¹Œà¸•à¹ˆà¸­ 1 à¸à¸¥à¸¸à¹ˆà¸¡ à¹‚à¸”à¸¢à¸¡à¸µà¸—à¸±à¹‰à¸‡à¹‚à¸„à¹‰à¸”à¸—à¸µà¹ˆà¸à¸£à¹‰à¸­à¸¡à¸£à¸±à¸™ à¹à¸¥à¸°à¸„à¸³à¸­à¸˜à¸´à¸šà¸²à¸¢à¸‡à¸²à¸™

â‘ Highlight: à¸ªà¸£à¸¸à¸›à¹„à¸®à¹„à¸¥à¸—à¹Œà¸—à¸µà¹ˆà¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆ bullet à¸ªà¸±à¹‰à¸™ à¹† à¸à¸£à¸°à¸Šà¸±à¸šà¹à¸•à¹ˆà¹„à¸”à¹‰à¹ƒà¸ˆà¸„à¸§à¸²à¸¡ à¸ˆà¸³à¸™à¸§à¸™à¸›à¸£à¸°à¸¡à¸²à¸“ 3-5 bullets à¸„à¸§à¸£à¸ˆà¸°à¹€à¸›à¹‡à¸™à¸‚à¹‰à¸­à¸„à¸´à¸”à¹€à¸«à¹‡à¸™ à¸à¸²à¸£à¸„à¹‰à¸™à¸à¸š à¸‚à¹‰à¸­à¸ªà¸£à¸¸à¸›à¸«à¸£à¸·à¸­à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ insight à¸™à¹ˆà¸²à¸ªà¸™à¹ƒà¸ˆà¸—à¸µà¹ˆà¸—à¸²à¸‡à¸à¸¥à¸¸à¹ˆà¸¡à¸„à¹‰à¸™à¸à¸šà¸ˆà¸²à¸à¸à¸²à¸£à¸—à¸³à¸à¸²à¸£à¸šà¹‰à¸²à¸™à¸„à¸£à¸±à¹‰à¸‡à¸™à¸µà¹‰

â‘ Introduction: à¸—à¸³ task à¸­à¸°à¹„à¸£ à¹€à¸Šà¹ˆà¸™ binary classification, single-label multi-class classification, multi-label classification, regression, segmentation, etc.

â‘ Data: 
- Data source, 
- EDA, 
- data preparation, 
- data pre-processing, 
- data post-processing, 
- data splitting (train/val/test) 
- à¸—à¸³à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£à¹ƒà¸«à¹‰à¹„à¸”à¹‰à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸—à¸µà¹ˆ balance à¹à¸¥à¸°à¸„à¸£à¸šà¸–à¹‰à¸§à¸™à¹ƒà¸™à¹à¸•à¹ˆà¸¥à¸°à¸„à¸¥à¸²à¸ª, 
- à¸£à¸°à¸šà¸¸à¹à¸™à¸§à¸—à¸²à¸‡à¸—à¸µà¹ˆà¸ˆà¸°à¹ƒà¸Šà¹‰à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²à¸”à¹‰à¸§à¸¢ (à¹‚à¸”à¸¢à¹€à¸‰à¸à¸²à¸°à¸‡à¸²à¸™ classification)

â‘ Network architecture: à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸•à¹ˆà¸²à¸‡ à¹† à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸—à¸µà¹ˆà¹€à¸¥à¸·à¸­à¸à¹ƒà¸Šà¹‰ (à¹€à¸Šà¹ˆà¸™ à¸ˆà¸³à¸™à¸§à¸™à¹à¸¥à¸°à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡à¸à¸²à¸£à¸§à¸²à¸‡ layer, à¸ˆà¸³à¸™à¸§à¸™ nodes, activation function, regularization) à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¸­à¸‡ network diagram à¸«à¸£à¸·à¸­à¸•à¸²à¸£à¸²à¸‡ (à¹‚à¸”à¸¢à¹ƒà¸ªà¹ˆà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹ƒà¸«à¹‰à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸à¸­à¸—à¸µà¹ˆà¸„à¸™à¸—à¸µà¹ˆà¸¡à¸²à¸­à¹ˆà¸²à¸™ à¸ˆà¸°à¸ªà¸²à¸¡à¸²à¸£à¸–à¹„à¸›à¸ªà¸£à¹‰à¸²à¸‡ network à¸•à¸²à¸¡à¹€à¸£à¸²à¹„à¸”à¹‰)

â‘ Training: à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸‚à¸­à¸‡à¸à¸²à¸£ train à¹à¸¥à¸° validate à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸£à¸§à¸¡à¸–à¸¶à¸‡à¸—à¸£à¸±à¸à¸¢à¸²à¸à¸£à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£ train à¹‚à¸¡à¹€à¸”à¸¥à¸«à¸™à¸¶à¹ˆà¸‡ à¹† à¹€à¸Šà¹ˆà¸™ training strategy (à¹€à¸Šà¹ˆà¸™ single loss, compound loss, two-step training, end-to-end training), loss, optimizer (learning rate, momentum, etc), batch size,
epoch, à¸£à¸¸à¹ˆà¸™à¹à¸¥à¸°à¸ˆà¸³à¸™à¸§à¸™ CPU à¸«à¸£à¸·à¸­ GPU à¸«à¸£à¸·à¸­ TPU à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰, à¹€à¸§à¸¥à¸²à¹‚à¸”à¸¢à¸›à¸£à¸°à¸¡à¸²à¸“à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ train à¹‚à¸¡à¹€à¸”à¸¥à¸«à¸™à¸¶à¹ˆà¸‡à¸•à¸±à¸§ à¸¯à¸¥à¸¯

â‘ Results: à¹à¸ªà¸”à¸‡à¸•à¸±à¸§à¹€à¸¥à¸‚à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹ƒà¸™à¸£à¸¹à¸›à¸‚à¸­à¸‡à¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢ meanÂ±SD à¹‚à¸”à¸¢à¹ƒà¸«à¹‰à¸—à¸³à¸à¸²à¸£à¹€à¸—à¸£à¸™à¹‚à¸¡à¹€à¸”à¸¥à¸”à¹‰à¸§à¸¢ initial random weights à¸—à¸µà¹ˆà¹à¸•à¸à¸•à¹ˆà¸²à¸‡à¸à¸±à¸™à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 3-5 à¸£à¸­à¸šà¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹„à¸”à¹‰à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢ 3-5 à¹‚à¸¡à¹€à¸”à¸¥à¸¡à¸²à¸«à¸²à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸à¸±à¸™, à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸à¸²à¸£ train à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸›à¹‡à¸™à¸à¸£à¸²à¸Ÿà¹€à¸—à¸µà¸¢à¸š train vs. validation, à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸§à¹ˆà¸²à¹€à¸à¸´à¸” underfit à¸«à¸£à¸·à¸­ overfit à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ, à¸­à¸˜à¸´à¸šà¸²à¸¢ evaluation metric à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸šà¸™ train/val/test sets à¸•à¸²à¸¡à¸„à¸§à¸²à¸¡à¹€à¸«à¸¡à¸²à¸°à¸ªà¸¡à¸‚à¸­à¸‡à¸›à¸±à¸à¸«à¸², à¸«à¸²à¸à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸£à¸²à¸à¸±à¸šà¹‚à¸¡à¹€à¸”à¸¥à¸­à¸·à¹ˆà¸™ à¹† (à¸‚à¸­à¸‡à¸„à¸™à¸­à¸·à¹ˆà¸™) à¸šà¸™ any standard benchmark dataset à¹„à¸”à¹‰à¸”à¹‰à¸§à¸¢à¸ˆà¸°à¸¢à¸´à¹ˆà¸‡à¸—à¸³à¹ƒà¸«à¹‰à¸‡à¸²à¸™à¸”à¸¹à¸™à¹ˆà¸²à¹€à¸Šà¸·à¹ˆà¸­à¸–à¸·à¸­à¸¢à¸´à¹ˆà¸‡à¸‚à¸¶à¹‰à¸™ à¹€à¸Šà¹ˆà¸™ à¹€à¸—à¸µà¸¢à¸šà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³ à¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰train à¹€à¸—à¸µà¸¢à¸šà¹€à¸§à¸¥à¸²à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ inference à¸šà¸™à¸‹à¸µà¸à¸µà¸¢à¸¹à¹à¸¥à¸°à¸ˆà¸µà¸à¸µà¸¢à¸¹ à¹€à¸—à¸µà¸¢à¸šà¸‚à¸™à¸²à¸”à¹‚à¸¡à¹€à¸”à¸¥ à¸¯à¸¥à¸¯

o (Optional) Ablation study: à¹ƒà¸™à¸à¸£à¸“à¸µà¸—à¸µà¹ˆà¹‚à¸¡à¹€à¸”à¸¥à¸¡à¸µà¸‚à¸™à¸²à¸”à¹ƒà¸«à¸à¹ˆà¹à¸¥à¸°à¸¡à¸µà¹‚à¸¡à¹€à¸”à¸¥à¸¢à¹ˆà¸­à¸¢à¸‹à¹‰à¸­à¸™à¸­à¸¢à¸¹à¹ˆà¸‚à¹‰à¸²à¸‡à¹ƒà¸™à¸­à¸µà¸à¸«à¸¥à¸²à¸¢à¸ªà¹ˆà¸§à¸™à¸ˆà¸™à¸—à¸³à¹ƒà¸«à¹‰à¸¢à¸²à¸à¸•à¹ˆà¸­à¸à¸²à¸£à¸ªà¸£à¸¸à¸›à¸§à¹ˆà¸²à¹‚à¸¡à¹€à¸”à¸¥à¸ªà¹ˆà¸§à¸™à¸¢à¹ˆà¸­à¸¢à¹ƒà¸”à¸¡à¸µà¸™à¸±à¸¢à¸ªà¸³à¸„à¸±à¸à¸¡à¸²à¸à¸™à¹‰à¸­à¸¢à¹à¸„à¹ˆà¹„à¸«à¸™à¸•à¹ˆà¸­à¸œà¸¥à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸šà¹‰à¸²à¸‡ à¹ƒà¸™à¸à¸£à¸“à¸µà¹€à¸«à¸¥à¹ˆà¸²à¸™à¸µà¹‰à¸™à¸´à¸¢à¸¡à¸—à¸³ ablation study à¹‚à¸”à¸¢à¸—à¸”à¸¥à¸­à¸‡à¸¥à¸šà¹‚à¸¡à¹€à¸”à¸¥à¸¢à¹ˆà¸­à¸¢à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™à¸­à¸­à¸ à¹à¸¥à¹‰à¸§ train à¹‚à¸¡à¹€à¸”à¸¥à¸”à¸±à¸‡à¸à¸¥à¹ˆà¸²à¸§à¹ƒà¸«à¸¡à¹ˆà¹€à¸à¸·à¹ˆà¸­à¸”à¸¹à¸§à¹ˆà¸²à¸à¸²à¸£à¸”à¸¶à¸‡à¸­à¸­à¸à¸™à¸µà¹‰à¸¡à¸µà¸œà¸¥à¸—à¸³à¹ƒà¸«à¹‰à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹‚à¸¡à¹€à¸”à¸¥à¸”à¸µà¸‚à¸¶à¹‰à¸™à¸«à¸£à¸·à¸­à¹à¸¢à¹ˆà¸¥à¸‡à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£ à¸–à¹‰à¸²à¸ªà¹ˆà¸§à¸™à¹„à¸«à¸™à¸”à¸¶à¸‡à¸­à¸­à¸à¹à¸¥à¹‰à¸§à¹‚à¸¡à¹€à¸”à¸¥à¸œà¸¥à¹à¸¢à¹ˆà¸¥à¸‡à¸¡à¸²à¸à¹à¸ªà¸”à¸‡à¸§à¹ˆà¸²à¸ªà¹ˆà¸§à¸™à¸™à¸±à¹‰à¸™à¸¡à¸µà¸„à¸§à¸²à¸¡à¸ªà¸³à¸„à¸±à¸à¸•à¹ˆà¸­à¹‚à¸¡à¹€à¸”à¸¥ à¸«à¹‰à¸²à¸¡à¹€à¸­à¸²à¸­à¸­à¸ à¹à¸•à¹ˆà¸–à¹‰à¸²à¸ªà¹ˆà¸§à¸™à¹„à¸«à¸™à¸”à¸¶à¸‡à¸­à¸­à¸à¹à¸¥à¹‰à¸§à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¹‚à¸¡à¹€à¸”à¸¥à¹€à¸«à¸¡à¸·à¸­à¸™à¹€à¸”à¸´à¸¡à¸à¹‡à¹à¸ªà¸”à¸‡à¸§à¹ˆà¸²à¸ªà¹ˆà¸§à¸™à¸™à¸±à¹‰à¸™à¹„à¸¡à¹ˆà¸¡à¸µà¸„à¸§à¸²à¸¡à¸ˆà¸³à¹€à¸›à¹‡à¸™à¸•à¹ˆà¸­à¹‚à¸¡à¹€à¸”à¸¥ à¹€à¸£à¸²à¸ªà¸²à¸¡à¸²à¸£à¸–à¸¥à¸šà¸­à¸­à¸à¹€à¸à¸·à¹ˆà¸­à¸¥à¸”à¸‚à¸™à¸²à¸”à¹à¸¥à¸°à¸„à¸§à¸²à¸¡à¸‹à¸±à¸šà¸‹à¹‰à¸­à¸™à¸‚à¸­à¸‡à¹‚à¸¡à¹€à¸”à¸¥à¸¥à¸‡à¹„à¸”à¹‰

â‘ Discussion: à¸­à¸ à¸´à¸›à¸£à¸²à¸¢à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸—à¸µà¹ˆà¹„à¸”à¹‰à¸§à¹ˆà¸²à¸¡à¸µà¸­à¸°à¹„à¸£à¹€à¸›à¹‡à¸™à¹„à¸›à¸•à¸²à¸¡à¸ªà¸¡à¸¡à¸•à¸´à¸à¸²à¸™ à¸«à¸£à¸·à¸­à¸¡à¸µà¸­à¸°à¹„à¸£à¸œà¸´à¸”à¸„à¸²à¸” à¹„à¸¡à¹ˆà¹€à¸›à¹‡à¸™à¹„à¸›à¸•à¸²à¸¡à¸ªà¸¡à¸¡à¸•à¸´à¸à¸²à¸™à¸šà¹‰à¸²à¸‡, à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¸§à¹ˆà¸²à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸œà¸´à¸”à¸„à¸²à¸”à¸«à¸£à¸·à¸­à¸œà¸´à¸”à¸›à¸à¸•à¸´à¸™à¸±à¹‰à¸™à¸™à¹ˆà¸²à¸ˆà¸°à¹€à¸à¸´à¸”à¸ˆà¸²à¸à¸­à¸°à¹„à¸£, à¹ƒà¸™à¸à¸£à¸“à¸µà¸—à¸µà¹ˆ dataset à¸¡à¸µà¸›à¸±à¸à¸«à¸² (à¹€à¸Šà¹ˆà¸™à¸à¸£à¸“à¸µ imbalanced dataset) à¸„à¸§à¸£à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸”à¹‰à¸§à¸¢à¸§à¹ˆà¸²à¸§à¸´à¸˜à¸µà¹à¸à¹‰à¸—à¸µà¹ˆà¹€à¸£à¸²à¹ƒà¸Šà¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹à¸à¹‰à¸›à¸±à¸à¸«à¸²à¸‚à¸­à¸‡ dataset à¹„à¸”à¹‰à¸ˆà¸£à¸´à¸‡à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ

â‘ Conclusion: à¸ªà¸£à¸¸à¸›à¸œà¸¥à¸‚à¸­à¸‡à¸à¸²à¸£à¸šà¹‰à¸²à¸™à¸™à¸µà¹‰ à¹‚à¸”à¸¢à¹€à¸™à¹‰à¸™à¸à¸²à¸£à¸•à¸­à¸šà¹‚à¸ˆà¸—à¸¢à¹Œà¸›à¸±à¸à¸«à¸² (research question) à¸«à¸£à¸·à¸­à¸ˆà¸¸à¸”à¸›à¸£à¸°à¸ªà¸‡à¸„à¹Œà¸«à¸¥à¸±à¸ (objective) à¸‚à¸­à¸‡à¸à¸²à¸£à¸šà¹‰à¸²à¸™à¹à¸•à¹ˆà¸¥à¸°à¸„à¸£à¸±à¹‰à¸‡

â‘ References: à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¹„à¸¥à¸šà¸£à¸²à¸£à¸µà¸—à¸µà¹ˆà¹ƒà¸Šà¹‰ (à¸à¸£à¹‰à¸­à¸¡à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™), à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¹€à¸—à¸„à¸™à¸´à¸„à¸—à¸µà¹ˆà¸¢à¸·à¸¡à¸¡à¸²à¹ƒà¸Šà¹‰à¸ˆà¸²à¸à¹€à¸›à¹€à¸›à¸­à¸£à¹Œ, à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¹‚à¸„à¹‰à¸”à¸«à¸£à¸·à¸­à¸£à¸¹à¸›à¸ à¸²à¸à¸—à¸µà¹ˆà¸«à¸¢à¸´à¸šà¸¢à¸·à¸¡à¸¡à¸²à¹ƒà¸Šà¹‰à¸ˆà¸²à¸ github à¸«à¸£à¸·à¸­à¸ˆà¸²à¸à¸—à¸µà¹ˆà¸­à¸·à¹ˆà¸™ à¹†

â‘ Citing: à¹ƒà¸™à¸à¸£à¸“à¸µà¸—à¸µà¹ˆà¸¡à¸µà¸„à¸™à¸­à¸¢à¸²à¸ cite (à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡) à¸‡à¸²à¸™à¸«à¸£à¸·à¸­ dataset à¸‚à¸­à¸‡à¹€à¸£à¸² à¹€à¸£à¸²à¸­à¸¢à¸²à¸à¹ƒà¸«à¹‰à¹€à¸‚à¸² cite à¹€à¸£à¸²à¸§à¹ˆà¸²à¸­à¸¢à¹ˆà¸²à¸‡à¹„à¸£ à¸ªà¹ˆà¸§à¸™à¹ƒà¸«à¸à¹ˆà¸™à¸´à¸¢à¸¡à¹€à¸‚à¸µà¸¢à¸™à¹ƒà¸™à¸£à¸¹à¸›à¹à¸šà¸šà¸‚à¸­à¸‡ bibtex format à¸•à¸²à¸¡à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¹ƒà¸™à¸ à¸²à¸

â‘ à¸£à¸²à¸¢à¸Šà¸·à¹ˆà¸­à¸ªà¸¡à¸²à¸Šà¸´à¸à¸à¸¥à¸¸à¹ˆà¸¡ à¸à¸£à¹‰à¸­à¸¡ contribution percentage à¸‚à¸­à¸‡à¸ªà¸¡à¸²à¸Šà¸´à¸à¹à¸•à¹ˆà¸¥à¸°à¸„à¸™ à¹à¸¥à¸°à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¸à¸²à¸£à¹à¸šà¹ˆà¸‡à¸‡à¸²à¸™ à¸—à¸±à¹‰à¸‡à¸™à¸µà¹‰à¸ªà¸³à¸«à¸£à¸±à¸šà¸™à¸±à¸à¸¨à¸¶à¸à¸©à¸²à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸­à¸¢à¸²à¸à¸£à¸°à¸šà¸¸à¸Šà¸·à¹ˆà¸­à¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥à¹€à¸•à¹‡à¸¡à¹ƒà¸™à¸¥à¸´à¸‡à¸à¹Œà¸ªà¸²à¸˜à¸²à¸£à¸“à¸° à¸ªà¸²à¸¡à¸²à¸£à¸–à¸£à¸°à¸šà¸¸à¹à¸•à¹ˆà¸£à¸«à¸±à¸ªà¸™à¸±à¸à¸¨à¸¶à¸à¸©à¸² à¸«à¸£à¸·à¸­ à¸£à¸°à¸šà¸¸à¹€à¸‰à¸à¸²à¸°à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™à¸‚à¸­à¸‡à¸Šà¸·à¹ˆà¸­à¹à¸¥à¸°à¸šà¸²à¸‡à¸ªà¹ˆà¸§à¸™à¸‚à¸­à¸‡à¸™à¸²à¸¡à¸ªà¸à¸¸à¸¥à¸à¹‡à¹„à¸”à¹‰

â‘ End credit: à¸‚à¸­à¹€à¸à¸´à¹ˆà¸¡à¸•à¸­à¸™à¸—à¹‰à¸²à¸¢à¸ªà¸¸à¸”à¹€à¸¥à¹‡à¸ à¹† à¸™à¸´à¸”à¸™à¸¶à¸‡à¸„à¹ˆà¸° à¸›à¸£à¸°à¸¡à¸²à¸“à¸§à¹ˆà¸² â€œà¸‡à¸²à¸™à¸Šà¸´à¹‰à¸™à¸™à¸µà¹‰à¹€à¸›à¹‡à¸™à¸ªà¹ˆà¸§à¸™à¸«à¸™à¸¶à¹ˆà¸‡à¸‚à¸­à¸‡ ...à¸Šà¸·à¹ˆà¸­à¸§à¸´à¸Šà¸²... ...à¸Šà¸·à¹ˆà¸­à¸«à¸¥à¸±à¸à¸ªà¸¹à¸•à¸£... ...à¸Šà¸·à¹ˆà¸­à¸¡à¸«à¸²à¸¥à¸±à¸¢...â€ (à¹€à¸à¸·à¹ˆà¸­à¹€à¸›à¹‡à¸™à¸à¸²à¸£à¸›à¸£à¸°à¸Šà¸²à¸ªà¸±à¸¡à¸à¸±à¸™à¸˜à¹Œà¸«à¸¥à¸±à¸à¸ªà¸¹à¸•à¸£à¹à¸¥à¸°à¸„à¸“à¸°à¹„à¸›à¹ƒà¸™à¸•à¸±à¸§)

***
3. à¸à¸²à¸£à¹à¸ªà¸”à¸‡à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹€à¸—à¸µà¸¢à¸š train vs. validation (à¹€à¸Šà¹ˆà¸™ loss, accuracy) à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™à¹„à¸›à¹„à¸”à¹‰à¸„à¸§à¸£à¹à¸ªà¸”à¸‡à¹„à¸§à¹‰à¹ƒà¸™à¸à¸£à¸²à¸Ÿà¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¸ªà¸²à¸¡à¸²à¸£à¸–à¹€à¸—à¸µà¸¢à¸š scale à¸„à¹ˆà¸²à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹à¸¥à¸°à¸”à¸¹ underfit / overfit à¹„à¸”à¹‰à¸‡à¹ˆà¸²à¸¢
4. à¹ƒà¸™à¸à¸²à¸£à¸à¸¥à¹ˆà¸²à¸§à¸–à¸¶à¸‡à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸«à¸£à¸·à¸­à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¹ƒà¸” à¹† à¹„à¸¡à¹ˆà¸§à¹ˆà¸²à¸ˆà¸°à¹€à¸›à¹‡à¸™à¹ƒà¸™à¹€à¸™à¸·à¹‰à¸­à¸„à¸§à¸²à¸¡ à¹ƒà¸™à¸•à¸²à¸£à¸²à¸‡ à¸«à¸£à¸·à¸­à¹ƒà¸™à¸£à¸¹à¸›à¸ à¸²à¸ à¹ƒà¸«à¹‰à¸£à¸°à¸šà¸¸à¹ƒà¸«à¹‰à¸Šà¸±à¸”à¹€à¸ˆà¸™à¹€à¸ªà¸¡à¸­à¸§à¹ˆà¸²à¸ªà¸´à¹ˆà¸‡à¸—à¸µà¹ˆà¸à¸¥à¹ˆà¸²à¸§à¸–à¸¶à¸‡à¸™à¸±à¹‰à¸™à¹€à¸›à¹‡à¸™à¸œà¸¥à¸¥à¸±à¸à¸˜à¹Œà¸šà¸™ train set à¸«à¸£à¸·à¸­ val set à¸«à¸£à¸·à¸­ test set
5. à¹ƒà¸™à¸à¸²à¸£à¸à¸¥à¹ˆà¸²à¸§à¸–à¸¶à¸‡à¸œà¸¥à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¸„à¹ˆà¸²à¸•à¹ˆà¸²à¸‡ à¹† à¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸à¸—à¸µà¹ˆà¸¡à¸²à¸‚à¸­à¸‡à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¹à¸¥à¸°à¸­à¸˜à¸´à¸šà¸²à¸¢à¸§à¸´à¸˜à¸µà¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“à¹„à¸§à¹‰à¹€à¸ªà¸¡à¸­ à¹€à¸Šà¹ˆà¸™ â€œà¸„à¹ˆà¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸‚à¸­à¸‡ xxxâ€ à¸à¹‡à¸•à¹‰à¸­à¸‡à¸­à¸˜à¸´à¸šà¸²à¸¢à¸§à¹ˆà¸²à¸¡à¸µà¸à¸²à¸£à¹ƒà¸Šà¹‰à¸„à¹ˆà¸²à¸­à¸°à¹„à¸£à¸ˆà¸²à¸à¹„à¸«à¸™à¸à¸µà¹ˆà¸„à¹ˆà¸²à¸šà¹‰à¸²à¸‡à¸™à¸³à¸¡à¸²à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸à¸±à¸™
6. à¸£à¸°à¸§à¸±à¸‡à¸§à¹ˆà¸²à¸à¸²à¸£à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹ƒà¸” à¹† à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™à¹„à¸›à¸šà¸™à¸à¸·à¹‰à¸™à¸à¸²à¸™à¸‚à¸­à¸‡à¹€à¸‡à¸·à¹ˆà¸­à¸™à¹„à¸‚à¸—à¸µà¹ˆà¸¢à¸¸à¸•à¸´à¸˜à¸£à¸£à¸¡à¸•à¹ˆà¸­à¸„à¸¹à¹ˆà¹€à¸—à¸µà¸¢à¸š à¹€à¸Šà¹ˆà¸™ à¸«à¸²à¸à¸ˆà¸°à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š training time à¸§à¹ˆà¸²à¹‚à¸¡à¹€à¸”à¸¥à¹„à¸«à¸™à¸¡à¸²à¸à¸™à¹‰à¸­à¸¢à¸à¸§à¹ˆà¸²à¸à¸±à¸™ à¸à¹‡à¸„à¸§à¸£à¸ˆà¸°à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¹€à¸›à¹‡à¸™ training time per one epoch (à¹‚à¸”à¸¢à¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸„à¹ˆà¸²à¸ˆà¸²à¸à¸«à¸¥à¸²à¸¢ à¹† epoch), à¸«à¸²à¸à¸ˆà¸°à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸š inference time per one sample à¸à¹‡à¸„à¸§à¸£à¸ˆà¸°à¸•à¹‰à¸­à¸‡à¹€à¸›à¹‡à¸™à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¹€à¸‰à¸¥à¸µà¹ˆà¸¢à¸¡à¸²à¸ˆà¸²à¸ test samples à¸Šà¸¸à¸”à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™à¸—à¸µà¹ˆà¸£à¸±à¸™à¸šà¸™ CPU à¸«à¸£à¸·à¸­ GPU à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™, à¸«à¸²à¸à¸ˆà¸°à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸§à¹ˆà¸² loss à¸¡à¸²à¸à¸«à¸£à¸·à¸­à¸™à¹‰à¸­à¸¢à¸à¸§à¹ˆà¸²à¸à¸±à¸™ à¸à¹‡à¸„à¸§à¸£à¸ˆà¸°à¹€à¸›à¸£à¸µà¸¢à¸šà¹€à¸—à¸µà¸¢à¸šà¸—à¸µà¹ˆà¸ªà¸¡à¸à¸²à¸£à¸à¸²à¸£à¸„à¸³à¸™à¸§à¸“ loss à¸ªà¸¡à¸à¸²à¸£à¹€à¸”à¸µà¸¢à¸§à¸à¸±à¸™ à¹€à¸›à¹‡à¸™à¸•à¹‰à¸™
7. à¸à¸²à¸£à¸­à¸ à¸´à¸›à¸£à¸²à¸¢à¸œà¸¥à¹à¸¥à¸°à¸à¸²à¸£à¸ªà¸£à¸¸à¸›à¸œà¸¥ à¸•à¹‰à¸­à¸‡à¸­à¹‰à¸²à¸‡à¸­à¸´à¸‡à¸à¸±à¸šà¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡à¸‚à¸­à¸‡à¹€à¸£à¸²à¸—à¸µà¹ˆà¹„à¸”à¹‰à¸­à¸­à¸à¸¡à¸²à¹€à¸›à¹‡à¸™à¸«à¸¥à¸±à¸ à¸¡à¸´à¹ƒà¸Šà¹ˆà¸à¸²à¸£à¸™à¸³à¸‚à¹‰à¸­à¸ªà¸£à¸¸à¸›à¸—à¸µà¹ˆà¹€à¸›à¹‡à¸™ general conclusion à¸ˆà¸²à¸à¸«à¸™à¸±à¸‡à¸ªà¸·à¸­ à¹à¸šà¸šà¹€à¸£à¸µà¸¢à¸™ à¸«à¸£à¸·à¸­à¸ˆà¸²à¸à¹à¸«à¸¥à¹ˆà¸‡à¸­à¸·à¹ˆà¸™ à¹† à¹ƒà¸™à¸­à¸´à¸™à¹€à¸—à¸­à¸£à¹Œà¹€à¸™à¹‡à¸• à¸¡à¸²à¹€à¸‚à¸µà¸¢à¸™à¸‹à¹‰à¸³à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸¡à¸µà¸œà¸¥à¸à¸²à¸£à¸—à¸”à¸¥à¸­à¸‡à¹ƒà¸” à¹† à¸‚à¸­à¸‡à¹€à¸£à¸²à¸¡à¸²à¸Šà¹ˆà¸§à¸¢à¸ªà¸™à¸±à¸šà¸ªà¸™à¸¸à¸™à¸‚à¹‰à¸­à¸ªà¸£à¸¸à¸›à¸”à¸±à¸‡à¸à¸¥à¹ˆà¸²à¸§
************** THE END **************-->
